{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QYRnowpl8ySC",
        "ZrS8n8EHAbyd"
      ],
      "authorship_tag": "ABX9TyO6Vw/znNkemz10TDEJtHr3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swap1984/-Bag-of-Words-N-gram-NLP-Feature-Extraction-Complete-Conceptual-Walkthrough/blob/main/Bag_of_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJq4NYTuLnD0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for Bag of Words embedding\n",
        "\n"
      ],
      "metadata": {
        "id": "QYRnowpl8ySC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Bag of Words (BoW): Method of Operation**\n",
        "\n",
        "Method of Operation:\n",
        "\n",
        "The Bag of Words (BoW) model is a simple and widely used technique for text representation. It converts a text into a matrix where:\n",
        "\n",
        "Rows represent documents (or sentences, or any text unit).\n",
        "Columns represent unique words (or bigrams, trigrams, etc.).\n",
        "The values in the matrix represent the frequency (or count) of each word in each document.\n",
        "\n",
        "Steps:\n",
        "\n",
        "Tokenization: The text is broken down into individual words (or tokens).\n",
        "Vocabulary Building: A vocabulary (set of unique words) is created from the tokens.\n",
        "\n",
        "Frequency Count: Each word in the vocabulary is counted for its occurrences in the document.\n",
        "\n",
        "**Advantages of BoW:**\n",
        "\n",
        "Simplicity: BoW is easy to understand and implement.\n",
        "\n",
        "Efficient for Smaller Datasets: Works well for small text data, especially when there's not much need for understanding context or word order.\n",
        "\n",
        "No Need for Pre-trained Models: It doesn’t require pre-trained word embeddings, so it's quick to generate.\n",
        "\n",
        "**Disadvantages of BoW:**\n",
        "\n",
        "Ignores Context: It doesn't capture the context or word order (e.g., \"dog bites man\" and \"man bites dog\" will be treated similarly).\n",
        "\n",
        "Sparsity: As vocabulary size increases, the matrix becomes sparse (many 0s) for larger datasets, which can increase computational cost.\n",
        "\n",
        "High Dimensionality: BoW creates a large feature space, which can make training machine learning models harder.\n",
        "\n",
        "Assumes All Words are Equally Important: It only considers the frequency of words, ignoring their importance or relevance.\n",
        "\n",
        "**Applications of BoW:**\n",
        "\n",
        "Text Classification: Frequently used in classification problems (spam detection, sentiment analysis) where contextual information isn't crucial.\n",
        "Information Retrieval: Search engines often use BoW for indexing documents and retrieving based on word matches.\n",
        "\n",
        "Topic Modeling: It can be a base input for algorithms like LDA (Latent Dirichlet Allocation) to find topics in a corpus."
      ],
      "metadata": {
        "id": "3XeVQJJ1M6PX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Initialising Libraries for  preprocessing the data for emmbedding\n"
      ],
      "metadata": {
        "id": "ZrS8n8EHAbyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import string #This module is used to remove punctuation from the text.\n",
        "import re #This regular expressions module is useful for operations like replacing repeated characters.\n",
        "from nltk.corpus import stopwords #  Provides a list of common English stopwords (e.g., \"the\", \"is\") that are generally not informative in text analysis.\n",
        "from nltk.tokenize import word_tokenize # to Tokenize a string into individual words.\n",
        "from nltk.stem import WordNetLemmatizer # to Convert words to their base (dictionary) form using lemmatization.\n"
      ],
      "metadata": {
        "id": "4knDdxQk8sdK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# using a paragraph as input . data =\"\"   \"\"\n",
        "data = \"\"\"Yes, life is full, there is life even underground,” he began again. “You wouldn’t believe, Alexey, how I want to live now, what a thirst for existence and consciousness has sprung up in me within these peeling walls… And what is suffering? I am not afraid of it, even if it were beyond reckoning. I am not afraid of it now. I was afraid of it before… And I seem to have such strength in me now, that I think I could stand anything, any suffering, only to be able to say and to repeat to myself every moment, ‘I exist.’ In thousands of agonies — I exist. I’m tormented on the rack — but I exist! Though I sit alone on a pillar — I exist! I see the sun, and if I don’t see the sun, I know it’s there. And there’s a whole life in that, in knowing that the sun is there.\"\"\""
      ],
      "metadata": {
        "id": "CpjVCi6q8pos"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the data"
      ],
      "metadata": {
        "id": "ZV6pYjaFczmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercasing\n",
        "data = data.lower()\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "I-5Jo2luCaWX",
        "outputId": "90171429-06d3-44a4-adfb-eaa03f0e4fff"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes, life is full, there is life even underground,” he began again. “you wouldn’t believe, alexey, how i want to live now, what a thirst for existence and consciousness has sprung up in me within these peeling walls… and what is suffering? i am not afraid of it, even if it were beyond reckoning. i am not afraid of it now. i was afraid of it before… and i seem to have such strength in me now, that i think i could stand anything, any suffering, only to be able to say and to repeat to myself every moment, ‘i exist.’ in thousands of agonies — i exist. i’m tormented on the rack — but i exist! though i sit alone on a pillar — i exist! i see the sun, and if i don’t see the sun, i know it’s there. and there’s a whole life in that, in knowing that the sun is there.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing ellipses and punctuation, including straight and curly quotation marks\n",
        "data = re.sub(r'\\.{2,}', '', data)  # Remove ellipses (two or more dots)\n",
        "data = re.sub(r'…', ' ', data)  # Replace Unicode ellipses with a space\n",
        "data = re.sub(r'\\s+', ' ', data)  # Replace multiple spaces with a single space\n",
        "data = re.sub(r'\\.\\.\\.+', '', data)  # Remove ellipses\n",
        "punctuation = string.punctuation + \"“”‘’—\"  # Include curly quotes and em dash\n",
        "data= data.translate(str.maketrans(\"\", \"\", punctuation))# Removing punctuation\n",
        "data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "cUFkHG1rC7Lm",
        "outputId": "c08839b7-44aa-4089-ec3f-01eebcad1f6e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes life is full there is life even underground he began again you wouldnt believe alexey how i want to live now what a thirst for existence and consciousness has sprung up in me within these peeling walls and what is suffering i am not afraid of it even if it were beyond reckoning i am not afraid of it now i was afraid of it before and i seem to have such strength in me now that i think i could stand anything any suffering only to be able to say and to repeat to myself every moment i exist in thousands of agonies  i exist im tormented on the rack  but i exist though i sit alone on a pillar  i exist i see the sun and if i dont see the sun i know its there and theres a whole life in that in knowing that the sun is there'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "i was getting the ellipses even after including the ellipsees removing code so i used the unicode ellipses removal method by converting them into spaces and then the space removing method to get rid of the entire punctuation and formatting of the data."
      ],
      "metadata": {
        "id": "tPPigRUQOlFp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "as seen above all the punctuation marks were to be removed but we see that the curly quotation marks and hyphen and dots are still there so adding the same to the string libraray and processing the data."
      ],
      "metadata": {
        "id": "Al2Z_r2VFxkE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "thus we see that all punctuation marks have been removed"
      ],
      "metadata": {
        "id": "UQCckoxKGax5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')  # Download the stopwords resource"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9yu0avJHYuS",
        "outputId": "bf8d6c98-e181-46fd-aa8d-d9e90664d8e6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "data = \" \".join([word for word in data.split() if word not in stop_words])\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "7OEQheZ6GgXf",
        "outputId": "0ce3dbfb-4b9e-469c-96a8-dd7a30d28b83"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes life full life even underground began wouldnt believe alexey want live thirst existence consciousness sprung within peeling walls suffering afraid even beyond reckoning afraid afraid seem strength think could stand anything suffering able say repeat every moment exist thousands agonies exist im tormented rack exist though sit alone pillar exist see sun dont see sun know theres whole life knowing sun'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # required as an error occured during tokenisation\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovmcj83KKWIr",
        "outputId": "33189782-a65d-4f0b-a0c5-d1936d68f4b3"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "tokens = word_tokenize(data)\n",
        "tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_EUj1luJvQz",
        "outputId": "d67ee46c-5fc4-487a-cb86-91f84072e220"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yes',\n",
              " 'life',\n",
              " 'full',\n",
              " 'life',\n",
              " 'even',\n",
              " 'underground',\n",
              " 'began',\n",
              " 'wouldnt',\n",
              " 'believe',\n",
              " 'alexey',\n",
              " 'want',\n",
              " 'live',\n",
              " 'thirst',\n",
              " 'existence',\n",
              " 'consciousness',\n",
              " 'sprung',\n",
              " 'within',\n",
              " 'peeling',\n",
              " 'walls',\n",
              " 'suffering',\n",
              " 'afraid',\n",
              " 'even',\n",
              " 'beyond',\n",
              " 'reckoning',\n",
              " 'afraid',\n",
              " 'afraid',\n",
              " 'seem',\n",
              " 'strength',\n",
              " 'think',\n",
              " 'could',\n",
              " 'stand',\n",
              " 'anything',\n",
              " 'suffering',\n",
              " 'able',\n",
              " 'say',\n",
              " 'repeat',\n",
              " 'every',\n",
              " 'moment',\n",
              " 'exist',\n",
              " 'thousands',\n",
              " 'agonies',\n",
              " 'exist',\n",
              " 'im',\n",
              " 'tormented',\n",
              " 'rack',\n",
              " 'exist',\n",
              " 'though',\n",
              " 'sit',\n",
              " 'alone',\n",
              " 'pillar',\n",
              " 'exist',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'dont',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'know',\n",
              " 'theres',\n",
              " 'whole',\n",
              " 'life',\n",
              " 'knowing',\n",
              " 'sun']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J8EQfaf0Kx2d"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lemmatization to convert the worts to their root form\n",
        "import nltk\n",
        "nltk.download('wordnet') #required as the error occured during lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8Xf-l1WKpdV",
        "outputId": "c493817d-33fb-45ca-de0e-823a7867d720"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yes',\n",
              " 'life',\n",
              " 'full',\n",
              " 'life',\n",
              " 'even',\n",
              " 'underground',\n",
              " 'began',\n",
              " 'wouldnt',\n",
              " 'believe',\n",
              " 'alexey',\n",
              " 'want',\n",
              " 'live',\n",
              " 'thirst',\n",
              " 'existence',\n",
              " 'consciousness',\n",
              " 'sprung',\n",
              " 'within',\n",
              " 'peeling',\n",
              " 'wall',\n",
              " 'suffering',\n",
              " 'afraid',\n",
              " 'even',\n",
              " 'beyond',\n",
              " 'reckoning',\n",
              " 'afraid',\n",
              " 'afraid',\n",
              " 'seem',\n",
              " 'strength',\n",
              " 'think',\n",
              " 'could',\n",
              " 'stand',\n",
              " 'anything',\n",
              " 'suffering',\n",
              " 'able',\n",
              " 'say',\n",
              " 'repeat',\n",
              " 'every',\n",
              " 'moment',\n",
              " 'exist',\n",
              " 'thousand',\n",
              " 'agony',\n",
              " 'exist',\n",
              " 'im',\n",
              " 'tormented',\n",
              " 'rack',\n",
              " 'exist',\n",
              " 'though',\n",
              " 'sit',\n",
              " 'alone',\n",
              " 'pillar',\n",
              " 'exist',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'dont',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'know',\n",
              " 'there',\n",
              " 'whole',\n",
              " 'life',\n",
              " 'knowing',\n",
              " 'sun']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the lemmatized output still contains the words with suffixes. We will have to perform Parts of speech (POS) tagging for this . thus we will perform following actions\n"
      ],
      "metadata": {
        "id": "nOPF6cTOQkfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import pos_tag\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "#Function to get the WordNet POS tag for lemmatization\n",
        "def get_wordnet_pos(tag):\n",
        "    if tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # Default to noun if no match\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7lXCgo2Q3oh",
        "outputId": "90a39708-e5e2-4b2b-b225-816d1bea7736"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(data)\n",
        "pos_tags = pos_tag(tokens)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(token, get_wordnet_pos(pos)) for token, pos in pos_tags]\n",
        "lemmatized_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcZHxllcQ3-T",
        "outputId": "e88a7108-9171-4458-cfad-49ba0ac34d05"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yes',\n",
              " 'life',\n",
              " 'full',\n",
              " 'life',\n",
              " 'even',\n",
              " 'underground',\n",
              " 'begin',\n",
              " 'wouldnt',\n",
              " 'believe',\n",
              " 'alexey',\n",
              " 'want',\n",
              " 'live',\n",
              " 'thirst',\n",
              " 'existence',\n",
              " 'consciousness',\n",
              " 'sprung',\n",
              " 'within',\n",
              " 'peel',\n",
              " 'wall',\n",
              " 'suffer',\n",
              " 'afraid',\n",
              " 'even',\n",
              " 'beyond',\n",
              " 'reckon',\n",
              " 'afraid',\n",
              " 'afraid',\n",
              " 'seem',\n",
              " 'strength',\n",
              " 'think',\n",
              " 'could',\n",
              " 'stand',\n",
              " 'anything',\n",
              " 'suffer',\n",
              " 'able',\n",
              " 'say',\n",
              " 'repeat',\n",
              " 'every',\n",
              " 'moment',\n",
              " 'exist',\n",
              " 'thousand',\n",
              " 'agony',\n",
              " 'exist',\n",
              " 'im',\n",
              " 'torment',\n",
              " 'rack',\n",
              " 'exist',\n",
              " 'though',\n",
              " 'sit',\n",
              " 'alone',\n",
              " 'pillar',\n",
              " 'exist',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'dont',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'know',\n",
              " 'theres',\n",
              " 'whole',\n",
              " 'life',\n",
              " 'know',\n",
              " 'sun']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen there are repeated word in the corpus now.. we will keep only the unique words\n"
      ],
      "metadata": {
        "id": "JpBHGti4S-1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove duplicates while preserving order\n",
        "unique_tokens = list(dict.fromkeys(lemmatized_tokens))\n",
        "unique_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0tr8e2XYS9pD",
        "outputId": "bdf0e945-f8b9-4b45-9b15-7b4d50d92576"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yes',\n",
              " 'life',\n",
              " 'full',\n",
              " 'even',\n",
              " 'underground',\n",
              " 'begin',\n",
              " 'wouldnt',\n",
              " 'believe',\n",
              " 'alexey',\n",
              " 'want',\n",
              " 'live',\n",
              " 'thirst',\n",
              " 'existence',\n",
              " 'consciousness',\n",
              " 'sprung',\n",
              " 'within',\n",
              " 'peel',\n",
              " 'wall',\n",
              " 'suffer',\n",
              " 'afraid',\n",
              " 'beyond',\n",
              " 'reckon',\n",
              " 'seem',\n",
              " 'strength',\n",
              " 'think',\n",
              " 'could',\n",
              " 'stand',\n",
              " 'anything',\n",
              " 'able',\n",
              " 'say',\n",
              " 'repeat',\n",
              " 'every',\n",
              " 'moment',\n",
              " 'exist',\n",
              " 'thousand',\n",
              " 'agony',\n",
              " 'im',\n",
              " 'torment',\n",
              " 'rack',\n",
              " 'though',\n",
              " 'sit',\n",
              " 'alone',\n",
              " 'pillar',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'dont',\n",
              " 'know',\n",
              " 'theres',\n",
              " 'whole']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing digits\n",
        "final_tokens = [token for token in unique_tokens if token.isalpha()]\n",
        "final_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuJAZpJLThEr",
        "outputId": "1f4a143b-2496-4183-ae8b-d9a8f2c18ab6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yes',\n",
              " 'life',\n",
              " 'full',\n",
              " 'even',\n",
              " 'underground',\n",
              " 'begin',\n",
              " 'wouldnt',\n",
              " 'believe',\n",
              " 'alexey',\n",
              " 'want',\n",
              " 'live',\n",
              " 'thirst',\n",
              " 'existence',\n",
              " 'consciousness',\n",
              " 'sprung',\n",
              " 'within',\n",
              " 'peel',\n",
              " 'wall',\n",
              " 'suffer',\n",
              " 'afraid',\n",
              " 'beyond',\n",
              " 'reckon',\n",
              " 'seem',\n",
              " 'strength',\n",
              " 'think',\n",
              " 'could',\n",
              " 'stand',\n",
              " 'anything',\n",
              " 'able',\n",
              " 'say',\n",
              " 'repeat',\n",
              " 'every',\n",
              " 'moment',\n",
              " 'exist',\n",
              " 'thousand',\n",
              " 'agony',\n",
              " 'im',\n",
              " 'torment',\n",
              " 'rack',\n",
              " 'though',\n",
              " 'sit',\n",
              " 'alone',\n",
              " 'pillar',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'dont',\n",
              " 'know',\n",
              " 'theres',\n",
              " 'whole']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Removing digits\n",
        "final_tokens = [token for token in unique_tokens if token.isalpha()]\n",
        "final_tokens\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vewLVp8TlN2",
        "outputId": "77061ec1-f08a-4394-c47e-aacf323cfca4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yes',\n",
              " 'life',\n",
              " 'full',\n",
              " 'even',\n",
              " 'underground',\n",
              " 'begin',\n",
              " 'wouldnt',\n",
              " 'believe',\n",
              " 'alexey',\n",
              " 'want',\n",
              " 'live',\n",
              " 'thirst',\n",
              " 'existence',\n",
              " 'consciousness',\n",
              " 'sprung',\n",
              " 'within',\n",
              " 'peel',\n",
              " 'wall',\n",
              " 'suffer',\n",
              " 'afraid',\n",
              " 'beyond',\n",
              " 'reckon',\n",
              " 'seem',\n",
              " 'strength',\n",
              " 'think',\n",
              " 'could',\n",
              " 'stand',\n",
              " 'anything',\n",
              " 'able',\n",
              " 'say',\n",
              " 'repeat',\n",
              " 'every',\n",
              " 'moment',\n",
              " 'exist',\n",
              " 'thousand',\n",
              " 'agony',\n",
              " 'im',\n",
              " 'torment',\n",
              " 'rack',\n",
              " 'though',\n",
              " 'sit',\n",
              " 'alone',\n",
              " 'pillar',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'dont',\n",
              " 'know',\n",
              " 'theres',\n",
              " 'whole']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Handelling rare words which may not add much value thus can be removed\n",
        "\n",
        "from collections import Counter\n",
        "word_freq = Counter(final_tokens)\n",
        "final_tokens1 = [token for token in tokens if word_freq[token] > 1]\n",
        "final_tokens1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugG5uMN_UruA",
        "outputId": "24c4c226-4c48-441f-f0af-f406f1670ad8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "as seen in our corpus each word is unique and thus rare so our final token output is empty list.so moving ahead with the final tokens list for embedding."
      ],
      "metadata": {
        "id": "EwyvCBG-VZ0R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6GOvk_2fyVtg",
        "outputId": "d8a81870-bda6-444d-82b6-373a9f5aac78"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['yes',\n",
              " 'life',\n",
              " 'full',\n",
              " 'even',\n",
              " 'underground',\n",
              " 'begin',\n",
              " 'wouldnt',\n",
              " 'believe',\n",
              " 'alexey',\n",
              " 'want',\n",
              " 'live',\n",
              " 'thirst',\n",
              " 'existence',\n",
              " 'consciousness',\n",
              " 'sprung',\n",
              " 'within',\n",
              " 'peel',\n",
              " 'wall',\n",
              " 'suffer',\n",
              " 'afraid',\n",
              " 'beyond',\n",
              " 'reckon',\n",
              " 'seem',\n",
              " 'strength',\n",
              " 'think',\n",
              " 'could',\n",
              " 'stand',\n",
              " 'anything',\n",
              " 'able',\n",
              " 'say',\n",
              " 'repeat',\n",
              " 'every',\n",
              " 'moment',\n",
              " 'exist',\n",
              " 'thousand',\n",
              " 'agony',\n",
              " 'im',\n",
              " 'torment',\n",
              " 'rack',\n",
              " 'though',\n",
              " 'sit',\n",
              " 'alone',\n",
              " 'pillar',\n",
              " 'see',\n",
              " 'sun',\n",
              " 'dont',\n",
              " 'know',\n",
              " 'theres',\n",
              " 'whole']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "khcrffHsJCL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac91afa1-6214-41b2-f884-f33cf96786b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This will create unigrams and bigrams\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer(ngram_range=(1, 2))\n",
        "vectorizer.fit(final_tokens)\n",
        "unigrams_bigrams = vectorizer.get_feature_names_out()\n",
        "unigrams_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBRQr-K0Vtrd",
        "outputId": "eae91f4b-b943-434e-ba8f-5c70965a24a2"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['able', 'afraid', 'agony', 'alexey', 'alone', 'anything', 'begin',\n",
              "       'believe', 'beyond', 'consciousness', 'could', 'dont', 'even',\n",
              "       'every', 'exist', 'existence', 'full', 'im', 'know', 'life',\n",
              "       'live', 'moment', 'peel', 'pillar', 'rack', 'reckon', 'repeat',\n",
              "       'say', 'see', 'seem', 'sit', 'sprung', 'stand', 'strength',\n",
              "       'suffer', 'sun', 'theres', 'think', 'thirst', 'though', 'thousand',\n",
              "       'torment', 'underground', 'wall', 'want', 'whole', 'within',\n",
              "       'wouldnt', 'yes'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BOW embedding code"
      ],
      "metadata": {
        "id": "dqQXn6bPYIWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = \" \".join(final_tokens)\n",
        "text_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "nNLq7UssYL4b",
        "outputId": "42b5ee5e-dfdc-468c-be3a-4aa154136bc9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'yes life full even underground begin wouldnt believe alexey want live thirst existence consciousness sprung within peel wall suffer afraid beyond reckon seem strength think could stand anything able say repeat every moment exist thousand agony im torment rack though sit alone pillar see sun dont know theres whole'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BOW matrix\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vectorizer = CountVectorizer()\n",
        "import numpy as np\n",
        "bow_matrix = vectorizer.fit_transform([text_data])\n",
        "bow_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYNV0OayZHco",
        "outputId": "734276d2-ea6f-4753-f491-f69ca94b8c43"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
              "\twith 49 stored elements and shape (1, 49)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#BOW array\n",
        "bow_array = bow_matrix.toarray()\n",
        "bow_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAZ8XK1NZvoC",
        "outputId": "b95a87bb-8c5c-42e7-cda7-8df9e720d56a"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "        1, 1, 1, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Unigrams and Bigrams:\")\n",
        "print(unigrams_bigrams)  # List of unigrams and bigrams as features\n",
        "\n",
        "print(\"\\nBag of Words Matrix:\")\n",
        "print(bow_array)  # The BoW representation (counts of each unigram/bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UN7nqZccaarb",
        "outputId": "59f18515-e0b5-4f28-c524-4533567ab58b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigrams and Bigrams:\n",
            "['able' 'afraid' 'agony' 'alexey' 'alone' 'anything' 'begin' 'believe'\n",
            " 'beyond' 'consciousness' 'could' 'dont' 'even' 'every' 'exist'\n",
            " 'existence' 'full' 'im' 'know' 'life' 'live' 'moment' 'peel' 'pillar'\n",
            " 'rack' 'reckon' 'repeat' 'say' 'see' 'seem' 'sit' 'sprung' 'stand'\n",
            " 'strength' 'suffer' 'sun' 'theres' 'think' 'thirst' 'though' 'thousand'\n",
            " 'torment' 'underground' 'wall' 'want' 'whole' 'within' 'wouldnt' 'yes']\n",
            "\n",
            "Bag of Words Matrix:\n",
            "[[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 1 1 1 1 1 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Inference"
      ],
      "metadata": {
        "id": "RJnqqGF-d3_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis and interpretation\n",
        "Sparsity:\n",
        "\n",
        "Sparsity refers to the proportion of zero entries in the BoW matrix. In this case, there is no sparsity at all, as every word in your unigrams and bigrams has a frequency of 1.\n",
        "Normally, a BoW matrix is sparse when documents contain only a small subset of the entire vocabulary. This means that for most documents, many words (or bigrams) don't appear, and their corresponding frequency counts are zero.\n",
        "Since all the tokens in the above matrix have a frequency of 1, it suggests that each unigram or bigram in the vocabulary appeared exactly once in the text.\n",
        "\n",
        "Word Frequencies:\n",
        "\n",
        "The matrix shows that every token (both unigrams and bigrams) in our vocabulary has a frequency of 1. This suggests that each token occurred exactly once in the input text.\n",
        "Interpretation: The text was processed in such a way that no words were repeated (either due to tokenization, preprocessing, or the specific text structure). Hence, every word and combination of words has the same frequency.\n",
        "\n",
        "the preprocessing here has lead to an uncomman or rare BOW matrix with no sparsity and uniform frequency\n"
      ],
      "metadata": {
        "id": "gJsSvj90cN1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Output shown below is considering each sentence of the input para as a document and running the BOW code for the new set pf documents thus formed. The code is in other colab file  but is being run here.**"
      ],
      "metadata": {
        "id": "UWX5yGM98AL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run \"/content/Assignment_Bag_of_words_multiple_documents_at_same_time.ipynb\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0h-ZbSl53uC",
        "outputId": "087f9617-2b40-4f53-e91f-3a6277016d84"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['yes life full life even underground began', 'wouldnt believe alexey want live thirst existence consciousness sprung within peeling walls', 'suffering afraid even beyond reckoning', 'afraid', 'afraid seem strength think could stand anything suffering able say repeat every moment exist', 'thousands agoniesi exist', 'im tormented rack exist though sit alone pillar exist see sun dont see sun know theres whole life knowing sun']\n",
            "Feature Names (Vocabulary):\n",
            "['able' 'afraid' 'agoniesi' 'alexey' 'alone' 'anything' 'began' 'believe'\n",
            " 'beyond' 'consciousness' 'could' 'dont' 'even' 'every' 'exist'\n",
            " 'existence' 'full' 'im' 'know' 'knowing' 'life' 'live' 'moment' 'peeling'\n",
            " 'pillar' 'rack' 'reckoning' 'repeat' 'say' 'see' 'seem' 'sit' 'sprung'\n",
            " 'stand' 'strength' 'suffering' 'sun' 'theres' 'think' 'thirst' 'though'\n",
            " 'thousands' 'tormented' 'underground' 'walls' 'want' 'whole' 'within'\n",
            " 'wouldnt' 'yes']\n",
            "\n",
            "Bag of Words Matrix:\n",
            "[[0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0\n",
            "  0 0 0 1 0 0 0 0 1 1 0 1 1 0]\n",
            " [0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1\n",
            "  0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "  0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0 0 1 0 0 2 0 0 1 1 1 1 0 0 0 1 1 0 0 0 2 0 1 0 0 0 0\n",
            "  3 1 0 0 1 0 1 0 0 0 1 0 0 0]]\n",
            "Number of unique words in vocabulary: 50\n",
            "Shape of the BoW matrix: (7, 50)\n",
            "True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}